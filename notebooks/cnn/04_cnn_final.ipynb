{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 22:45:40,704] A new study created in memory with name: no-name-b8b8c644-3e30-4ff0-a0ff-747f46280eb4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 22:45:45,693] Trial 0 finished with value: 0.7450980392156863 and parameters: {'num_filters': 32, 'kernel_size': 12, 'stride': 2, 'dense_units': 128, 'dropout_rate': 0.09645630396838567, 'learning_rate': 0.00023167862312872177}. Best is trial 0 with value: 0.7450980392156863.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 22:45:55,182] Trial 1 finished with value: 0.7450980392156863 and parameters: {'num_filters': 64, 'kernel_size': 12, 'stride': 1, 'dense_units': 64, 'dropout_rate': 0.09772510535255806, 'learning_rate': 0.00044136506816796947}. Best is trial 0 with value: 0.7450980392156863.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 22:46:03,745] Trial 2 finished with value: 0.7647058823529411 and parameters: {'num_filters': 32, 'kernel_size': 4, 'stride': 2, 'dense_units': 256, 'dropout_rate': 0.08713025662595388, 'learning_rate': 0.00011212710145451034}. Best is trial 2 with value: 0.7647058823529411.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 22:46:10,939] Trial 3 finished with value: 0.7450980392156863 and parameters: {'num_filters': 32, 'kernel_size': 12, 'stride': 2, 'dense_units': 256, 'dropout_rate': 0.07147479454929678, 'learning_rate': 0.00019507928883512267}. Best is trial 2 with value: 0.7647058823529411.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 22:46:14,813] Trial 4 finished with value: 0.7647058823529411 and parameters: {'num_filters': 32, 'kernel_size': 8, 'stride': 2, 'dense_units': 128, 'dropout_rate': 0.0961339447730744, 'learning_rate': 0.0008268221162117252}. Best is trial 2 with value: 0.7647058823529411.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 22:46:19,965] Trial 5 finished with value: 0.7254901960784313 and parameters: {'num_filters': 32, 'kernel_size': 12, 'stride': 2, 'dense_units': 128, 'dropout_rate': 0.07252507276449362, 'learning_rate': 0.0002470007167831865}. Best is trial 2 with value: 0.7647058823529411.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 22:46:26,944] Trial 6 finished with value: 0.7450980392156863 and parameters: {'num_filters': 32, 'kernel_size': 8, 'stride': 2, 'dense_units': 256, 'dropout_rate': 0.09883616088813701, 'learning_rate': 0.00027937235319243386}. Best is trial 2 with value: 0.7647058823529411.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 22:47:18,383] Trial 7 finished with value: 0.7843137254901961 and parameters: {'num_filters': 128, 'kernel_size': 12, 'stride': 1, 'dense_units': 256, 'dropout_rate': 0.09563390827925078, 'learning_rate': 0.00020795371139822587}. Best is trial 7 with value: 0.7843137254901961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 22:47:28,475] Trial 8 finished with value: 0.7450980392156863 and parameters: {'num_filters': 64, 'kernel_size': 12, 'stride': 2, 'dense_units': 128, 'dropout_rate': 0.07240693674440399, 'learning_rate': 0.0006573313575045435}. Best is trial 7 with value: 0.7843137254901961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 22:47:42,296] Trial 9 finished with value: 0.7843137254901961 and parameters: {'num_filters': 32, 'kernel_size': 8, 'stride': 1, 'dense_units': 256, 'dropout_rate': 0.09123854401912826, 'learning_rate': 0.0007971523775618525}. Best is trial 7 with value: 0.7843137254901961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 22:48:05,042] Trial 10 finished with value: 0.7647058823529411 and parameters: {'num_filters': 128, 'kernel_size': 4, 'stride': 1, 'dense_units': 64, 'dropout_rate': 0.08073217388332228, 'learning_rate': 0.00013066297400830202}. Best is trial 7 with value: 0.7843137254901961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 22:49:12,717] Trial 11 finished with value: 0.7647058823529411 and parameters: {'num_filters': 128, 'kernel_size': 8, 'stride': 1, 'dense_units': 256, 'dropout_rate': 0.09052994030908802, 'learning_rate': 0.0004364887488542906}. Best is trial 7 with value: 0.7843137254901961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 22:50:06,711] Trial 12 finished with value: 0.7450980392156863 and parameters: {'num_filters': 128, 'kernel_size': 8, 'stride': 1, 'dense_units': 256, 'dropout_rate': 0.09123386376304468, 'learning_rate': 0.0001653374010885668}. Best is trial 7 with value: 0.7843137254901961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 22:51:06,664] Trial 13 finished with value: 0.7647058823529411 and parameters: {'num_filters': 128, 'kernel_size': 8, 'stride': 1, 'dense_units': 256, 'dropout_rate': 0.08187211761074216, 'learning_rate': 0.00044323906487469134}. Best is trial 7 with value: 0.7843137254901961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 22:51:54,609] Trial 14 finished with value: 0.7843137254901961 and parameters: {'num_filters': 128, 'kernel_size': 4, 'stride': 1, 'dense_units': 256, 'dropout_rate': 0.09270649488084848, 'learning_rate': 0.00034981028924524097}. Best is trial 7 with value: 0.7843137254901961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 22:52:14,006] Trial 15 finished with value: 0.6862745098039216 and parameters: {'num_filters': 64, 'kernel_size': 12, 'stride': 1, 'dense_units': 256, 'dropout_rate': 0.08671566036921316, 'learning_rate': 0.0009590106963682386}. Best is trial 7 with value: 0.7843137254901961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 22:52:33,496] Trial 16 finished with value: 0.6666666666666666 and parameters: {'num_filters': 128, 'kernel_size': 8, 'stride': 1, 'dense_units': 64, 'dropout_rate': 0.09366347975215515, 'learning_rate': 0.0006368855076345559}. Best is trial 7 with value: 0.7843137254901961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 22:53:44,932] Trial 17 finished with value: 0.7843137254901961 and parameters: {'num_filters': 128, 'kernel_size': 8, 'stride': 1, 'dense_units': 256, 'dropout_rate': 0.08897258991086733, 'learning_rate': 0.00017084383804986294}. Best is trial 7 with value: 0.7843137254901961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 22:54:01,774] Trial 18 finished with value: 0.7450980392156863 and parameters: {'num_filters': 32, 'kernel_size': 12, 'stride': 1, 'dense_units': 256, 'dropout_rate': 0.08283884502692593, 'learning_rate': 0.0005854147587865572}. Best is trial 7 with value: 0.7843137254901961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 22:54:11,388] Trial 19 finished with value: 0.7058823529411765 and parameters: {'num_filters': 64, 'kernel_size': 4, 'stride': 1, 'dense_units': 64, 'dropout_rate': 0.07662463632080184, 'learning_rate': 0.0003393379726657309}. Best is trial 7 with value: 0.7843137254901961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 22:55:05,421] Trial 20 finished with value: 0.7450980392156863 and parameters: {'num_filters': 128, 'kernel_size': 12, 'stride': 1, 'dense_units': 256, 'dropout_rate': 0.0997708417119193, 'learning_rate': 0.00013957140007387652}. Best is trial 7 with value: 0.7843137254901961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 22:56:23,312] Trial 21 finished with value: 0.7647058823529411 and parameters: {'num_filters': 128, 'kernel_size': 4, 'stride': 1, 'dense_units': 256, 'dropout_rate': 0.09281660329786014, 'learning_rate': 0.0003471178253614649}. Best is trial 7 with value: 0.7843137254901961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 22:57:50,637] Trial 22 finished with value: 0.7647058823529411 and parameters: {'num_filters': 128, 'kernel_size': 4, 'stride': 1, 'dense_units': 256, 'dropout_rate': 0.09422127332177972, 'learning_rate': 0.00020516027459048034}. Best is trial 7 with value: 0.7843137254901961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 22:58:56,990] Trial 23 finished with value: 0.7843137254901961 and parameters: {'num_filters': 128, 'kernel_size': 4, 'stride': 1, 'dense_units': 256, 'dropout_rate': 0.08928768520594765, 'learning_rate': 0.0005122209004257172}. Best is trial 7 with value: 0.7843137254901961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 23:00:20,026] Trial 24 finished with value: 0.7058823529411765 and parameters: {'num_filters': 128, 'kernel_size': 4, 'stride': 1, 'dense_units': 256, 'dropout_rate': 0.09483537648339056, 'learning_rate': 0.0002914898554529026}. Best is trial 7 with value: 0.7843137254901961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-02 23:00:32,872] Trial 25 finished with value: 0.7647058823529411 and parameters: {'num_filters': 32, 'kernel_size': 4, 'stride': 1, 'dense_units': 256, 'dropout_rate': 0.0924707806158096, 'learning_rate': 0.00035106103864998133}. Best is trial 7 with value: 0.7843137254901961.\n",
      "[W 2025-08-02 23:01:22,796] Trial 26 failed with parameters: {'num_filters': 128, 'kernel_size': 8, 'stride': 1, 'dense_units': 256, 'dropout_rate': 0.08475338206386861, 'learning_rate': 0.0008150808705696853} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tusharsingh/miniconda3/envs/ML_practice/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/lx/5td2g65s51s2qn_zywp584340000gn/T/ipykernel_294/771052429.py\", line 101, in objective\n",
      "    model.fit(train_gen,\n",
      "  File \"/Users/tusharsingh/miniconda3/envs/ML_practice/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tusharsingh/miniconda3/envs/ML_practice/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n",
      "    logs = self.train_function(iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tusharsingh/miniconda3/envs/ML_practice/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n",
      "    opt_outputs = multi_step_on_iterator(iterator)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tusharsingh/miniconda3/envs/ML_practice/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tusharsingh/miniconda3/envs/ML_practice/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 833, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tusharsingh/miniconda3/envs/ML_practice/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 878, in _call\n",
      "    results = tracing_compilation.call_function(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tusharsingh/miniconda3/envs/ML_practice/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 139, in call_function\n",
      "    return function._call_flat(  # pylint: disable=protected-access\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tusharsingh/miniconda3/envs/ML_practice/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1322, in _call_flat\n",
      "    return self._inference_function.call_preflattened(args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tusharsingh/miniconda3/envs/ML_practice/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n",
      "    flat_outputs = self.call_flat(*args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tusharsingh/miniconda3/envs/ML_practice/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n",
      "    outputs = self._bound_context.call_function(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tusharsingh/miniconda3/envs/ML_practice/lib/python3.11/site-packages/tensorflow/python/eager/context.py\", line 1683, in call_function\n",
      "    outputs = execute.execute(\n",
      "              ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tusharsingh/miniconda3/envs/ML_practice/lib/python3.11/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-08-02 23:01:22,810] Trial 26 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 111\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# --- Run Optuna Study ---\u001b[39;00m\n\u001b[32m    110\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m study.optimize(objective, n_trials=\u001b[32m50\u001b[39m)\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# --- Train Best Model ---\u001b[39;00m\n\u001b[32m    114\u001b[39m final_model = build_model(study.best_trial, input_shape=(X_train_np.shape[\u001b[32m1\u001b[39m], \u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ML_practice/lib/python3.11/site-packages/optuna/study/study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     _optimize(\n\u001b[32m    490\u001b[39m         study=\u001b[38;5;28mself\u001b[39m,\n\u001b[32m    491\u001b[39m         func=func,\n\u001b[32m    492\u001b[39m         n_trials=n_trials,\n\u001b[32m    493\u001b[39m         timeout=timeout,\n\u001b[32m    494\u001b[39m         n_jobs=n_jobs,\n\u001b[32m    495\u001b[39m         catch=\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[32m    496\u001b[39m         callbacks=callbacks,\n\u001b[32m    497\u001b[39m         gc_after_trial=gc_after_trial,\n\u001b[32m    498\u001b[39m         show_progress_bar=show_progress_bar,\n\u001b[32m    499\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ML_practice/lib/python3.11/site-packages/optuna/study/_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         _optimize_sequential(\n\u001b[32m     65\u001b[39m             study,\n\u001b[32m     66\u001b[39m             func,\n\u001b[32m     67\u001b[39m             n_trials,\n\u001b[32m     68\u001b[39m             timeout,\n\u001b[32m     69\u001b[39m             catch,\n\u001b[32m     70\u001b[39m             callbacks,\n\u001b[32m     71\u001b[39m             gc_after_trial,\n\u001b[32m     72\u001b[39m             reseed_sampler_rng=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     73\u001b[39m             time_start=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     74\u001b[39m             progress_bar=progress_bar,\n\u001b[32m     75\u001b[39m         )\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ML_practice/lib/python3.11/site-packages/optuna/study/_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = _run_trial(study, func, catch)\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ML_practice/lib/python3.11/site-packages/optuna/study/_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ML_practice/lib/python3.11/site-packages/optuna/study/_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = func(trial)\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 101\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     93\u001b[39m val_gen = GeneExpressionSequence(X_val_np, y_val_np, \n\u001b[32m     94\u001b[39m                                  batch_size=\u001b[32m128\u001b[39m,\n\u001b[32m     95\u001b[39m                                  shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     97\u001b[39m early_stop = EarlyStopping(monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m     98\u001b[39m                            patience=\u001b[32m10\u001b[39m, \n\u001b[32m     99\u001b[39m                            restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[32m    100\u001b[39m                            verbose=\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m model.fit(train_gen,\n\u001b[32m    102\u001b[39m          validation_data=val_gen,\n\u001b[32m    103\u001b[39m          epochs=\u001b[32m50\u001b[39m,\n\u001b[32m    104\u001b[39m          callbacks=[early_stop], verbose=\u001b[32m0\u001b[39m)\n\u001b[32m    106\u001b[39m y_pred = (model.predict(val_gen) > \u001b[32m0.5\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m).flatten()\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y_val_np, y_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ML_practice/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(*args, **kwargs)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ML_practice/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28mself\u001b[39m.train_function(iterator)\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ML_practice/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = multi_step_on_iterator(iterator)\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ML_practice/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(*args, **kwargs)\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ML_practice/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28mself\u001b[39m._call(*args, **kwds)\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ML_practice/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = tracing_compilation.call_function(\n\u001b[32m    879\u001b[39m     args, kwds, \u001b[38;5;28mself\u001b[39m._variable_creation_config\n\u001b[32m    880\u001b[39m )\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ML_practice/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m function._call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    140\u001b[39m     flat_inputs, captured_inputs=function.captured_inputs\n\u001b[32m    141\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ML_practice/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inference_function.call_preflattened(args)\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ML_practice/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28mself\u001b[39m.call_flat(*args)\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ML_practice/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m._bound_context.call_function(\n\u001b[32m    252\u001b[39m         \u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m    253\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    254\u001b[39m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.function_type.flat_outputs),\n\u001b[32m    255\u001b[39m     )\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ML_practice/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1683\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1681\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1682\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1683\u001b[39m   outputs = execute.execute(\n\u001b[32m   1684\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1685\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   1686\u001b[39m       inputs=tensor_inputs,\n\u001b[32m   1687\u001b[39m       attrs=attrs,\n\u001b[32m   1688\u001b[39m       ctx=\u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1689\u001b[39m   )\n\u001b[32m   1690\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1691\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1692\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1693\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1697\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1698\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ML_practice/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[32m     54\u001b[39m                                       inputs, attrs, num_outputs)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, Flatten, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "# --- Set Random Seed ---\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# --- Generator Class ---\n",
    "class GeneExpressionSequence(Sequence):\n",
    "    def __init__(self, X, y, batch_size=32, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs) \n",
    "        self.X = X.reshape(-1, X.shape[1], 1)\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.X))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        return self.X[batch_indices], self.y[batch_indices]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "# --- Model Builder for Optuna ---\n",
    "def build_model(trial, input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "\n",
    "    num_filters = trial.suggest_categorical(\"num_filters\", [32, 64,128])\n",
    "    kernel_size = trial.suggest_categorical(\"kernel_size\", [2, 4])\n",
    "    stride = trial.suggest_int(\"stride\", 1, 2)\n",
    "\n",
    "    model.add(Conv1D(filters=num_filters, kernel_size=kernel_size, strides=stride, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    dense_units = trial.suggest_categorical(\"dense_units\", [64, 128])\n",
    "    dropout_rate = (0.07)\n",
    "    learning_rate = (1e-3)\n",
    "\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# --- Load Variant Split ---\n",
    "base_path = Path(\"/Users/tusharsingh/Work/Project/tcga-mldl/results/data/data_splits\")\n",
    "variant_name = \"15pct_80\"\n",
    "data_path = base_path / variant_name\n",
    "\n",
    "X_train = pd.read_csv(data_path / \"X_train.csv\", index_col=0)\n",
    "X_test = pd.read_csv(data_path / \"X_test.csv\", index_col=0)\n",
    "y_train = pd.read_csv(data_path / \"y_train.csv\", index_col=0).squeeze()\n",
    "y_test = pd.read_csv(data_path / \"y_test.csv\", index_col=0).squeeze()\n",
    "\n",
    "# --- Split Test into Val + Final ---\n",
    "X_val_np, X_final_np, y_val_np, y_final_np = train_test_split(\n",
    "    X_test.values, y_test.values, test_size=0.5, stratify=y_test, random_state=SEED\n",
    ")\n",
    "X_train_np, y_train_np = X_train.values, y_train.values\n",
    "\n",
    "# --- Objective Function for Optuna ---\n",
    "def objective(trial):\n",
    "    model = build_model(trial, input_shape=(X_train_np.shape[1], 1))\n",
    "    train_gen = GeneExpressionSequence(X_train_np, y_train_np,\n",
    "                                        batch_size=128)\n",
    "    \n",
    "    val_gen = GeneExpressionSequence(X_val_np, y_val_np, \n",
    "                                     batch_size=128,\n",
    "                                     shuffle=False)\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', \n",
    "                               patience=10, \n",
    "                               restore_best_weights=True, \n",
    "                               verbose=0)\n",
    "    model.fit(train_gen,\n",
    "             validation_data=val_gen,\n",
    "             epochs=50,\n",
    "             callbacks=[early_stop], verbose=0)\n",
    "\n",
    "    y_pred = (model.predict(val_gen) > 0.5).astype(int).flatten()\n",
    "    return accuracy_score(y_val_np, y_pred)\n",
    "\n",
    "# --- Run Optuna Study ---\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# --- Train Best Model ---\n",
    "final_model = build_model(study.best_trial, input_shape=(X_train_np.shape[1], 1))\n",
    "train_gen = GeneExpressionSequence(X_train_np, y_train_np, batch_size=128)\n",
    "val_gen = GeneExpressionSequence(X_val_np, y_val_np, batch_size=128)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "final_model.fit(train_gen, validation_data=val_gen, epochs=50, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# --- Final Evaluation ---\n",
    "final_test_gen = GeneExpressionSequence(X_final_np, y_final_np, batch_size=128, shuffle=False)\n",
    "y_pred_final = (final_model.predict(final_test_gen) > 0.5).astype(int).flatten()\n",
    "\n",
    "print(\"\\n📊 Final Test Results on Held-Out Set\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y_final_np, y_pred_final), 4))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_final_np, y_pred_final, zero_division=0))\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_final_np, y_pred_final), annot=True, fmt='d', cmap=\"PuRd\")\n",
    "plt.title(f\"Confusion Matrix - {variant_name}\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
